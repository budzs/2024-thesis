{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, optimizers, Input, Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Ensure compatibility with different TensorFlow versions\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\MindRove_BZs\\\\Diploma\\\\processed_data_05Hz_no_norm\\\\'\n",
    "class_dir = 'C:\\\\Users\\\\MindRove_BZs\\\\Diploma\\\\classes\\\\'\n",
    "\n",
    "def load_data(patient_ids):\n",
    "    emg_data = {}\n",
    "    eeg_data = {}\n",
    "    for i in patient_ids:\n",
    "        with open(os.path.join(data_dir, f'normalized_filtered_emg_data_patient_{i}.pkl'), 'rb') as f:\n",
    "            patient_emg_data = pickle.load(f)\n",
    "            for key in patient_emg_data:\n",
    "                if isinstance(key, float) and key.is_integer():\n",
    "                    key = int(key)  \n",
    "                modified_key = f\"patient_{i}_{key}\"\n",
    "                emg_data[modified_key] = patient_emg_data[key]\n",
    "        \n",
    "        with open(os.path.join(data_dir, f'normalized_filtered_eeg_data_patient_{i}.pkl'), 'rb') as f:\n",
    "            patient_eeg_data = pickle.load(f)\n",
    "            for key in patient_eeg_data:\n",
    "                if isinstance(key, float) and key.is_integer():\n",
    "                    key = int(key)  \n",
    "                modified_key = f\"patient_{i}_{key}\"\n",
    "                eeg_data[modified_key] = patient_eeg_data[key]\n",
    "        print(f\"Size of eeg data after patient {i}: {len(eeg_data)}\")\n",
    "    \n",
    "    return emg_data, eeg_data\n",
    "\n",
    "def load_classes():\n",
    "    class_files = [f for f in os.listdir(class_dir) if f.endswith('.pickle')]\n",
    "    all_classes = {}\n",
    "    for file in class_files:\n",
    "        with open(os.path.join(class_dir, file), 'rb') as f:\n",
    "            classes_data = pickle.load(f)\n",
    "            identifier = file.split('_')[-1].replace('.pickle', '')\n",
    "            for key in classes_data:\n",
    "                modified_key = f\"patient_{identifier}_{key}\"\n",
    "                all_classes[modified_key] = classes_data[key]\n",
    "    return all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(emg_data, eeg_data):\n",
    "    channels_to_keep = np.r_[0:6, 7:8] \n",
    "\n",
    "    filtered_emg_data = {}\n",
    "    filtered_eeg_data = {}\n",
    "    for frame in emg_data:\n",
    "        if emg_data[frame].shape[1] >= 30 and eeg_data[frame].shape[1] >= 30:\n",
    "            min_length = 30\n",
    "            filtered_emg_data[frame] = emg_data[frame][:, :min_length]\n",
    "            filtered_eeg_data[frame] = eeg_data[frame][channels_to_keep][:, :min_length]\n",
    "    return filtered_emg_data, filtered_eeg_data\n",
    "\n",
    "\n",
    "def prepare_dataset(emg_data, eeg_data, all_classes):\n",
    "    filtered_emg_data, filtered_eeg_data = filter_data(emg_data, eeg_data)\n",
    "    X = []\n",
    "    y = []\n",
    "    for frame in all_classes.keys():\n",
    "        \n",
    "        if frame in filtered_emg_data and frame in filtered_eeg_data:\n",
    "            combined_data = np.concatenate((filtered_emg_data[frame], filtered_eeg_data[frame]), axis=0)\n",
    "            X.append(combined_data)\n",
    "            y.append(all_classes[frame])\n",
    "    X = np.array(X)\n",
    "    y = to_categorical(np.array(y))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "    \n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "\n",
    "class AdjustLearningRate(Callback):\n",
    "    def __init__(self, new_lr, epoch_to_adjust):\n",
    "        super(AdjustLearningRate, self).__init__()\n",
    "        self.new_lr = new_lr\n",
    "        self.epoch_to_adjust = epoch_to_adjust\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch == self.epoch_to_adjust:\n",
    "            old_lr = self.model.optimizer.learning_rate.numpy() \n",
    "            self.model.optimizer.learning_rate.assign(self.new_lr)\n",
    "            print(f\"\\nEpoch {epoch+1}: Adjusting learning rate from {old_lr} to {self.new_lr}.\")\n",
    "\n",
    "def cnn_model(lr=1e-5):\n",
    "    input_shape = (15, 30, 1)\n",
    "    num_classes = 8\n",
    "    \n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = layers.Flatten()(input_tensor)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    output_tensor = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "\n",
    "    opt = optimizers.Nadam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\", F1Score()])\n",
    "\n",
    "    #adjust_lr_callback = AdjustLearningRate(new_lr=new_lr, epoch_to_adjust=adjust_lr_epoch-1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot(loss, val_loss, acc, val_acc):\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc, 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_one_hot_encoding(y):\n",
    "    if len(y.shape) == 1:\n",
    "        n_classes = np.max(y) + 1\n",
    "        y = to_categorical(y, num_classes=n_classes)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_results(y_true, y_pred_classes, patient_ids, base_folder=\"C:\\\\Users\\\\MindRove_BZs\\\\Pictures\\\\\"):\n",
    "    correct_indices = np.where(y_true == y_pred_classes)[0]\n",
    "    incorrect_indices = np.where(y_true != y_pred_classes)[0]\n",
    "\n",
    "    correct_to_visualize = correct_indices[:3]  \n",
    "    incorrect_to_visualize = incorrect_indices[:3]  \n",
    "\n",
    "    def display_image(frame_number, patient_id, correct=True):\n",
    "        if patient_id == 5:\n",
    "            folder_name = f\"{base_folder}0507_patient_{patient_id}\"\n",
    "        if patient_id == 6:\n",
    "            folder_name = f\"{base_folder}0517_patient_{patient_id}\"\n",
    "        if patient_id == 7:\n",
    "            folder_name = f\"{base_folder}0522_patient_{patient_id}\"\n",
    "        if patient_id == 8:\n",
    "            folder_name = f\"{base_folder}0523_patient_{patient_id}\"\n",
    "        if patient_id == 9:\n",
    "            folder_name = f\"{base_folder}05231_patient_{patient_id}\"\n",
    "        if patient_id == 10:\n",
    "            folder_name = f\"{base_folder}05232_patient_{patient_id}\"\n",
    "        if patient_id == 11:\n",
    "            folder_name = f\"{base_folder}05233_patient_{patient_id}\"\n",
    "        file_name = f\"frame_{frame_number}_*.png\"  \n",
    "        full_path = os.path.join(folder_name, file_name)\n",
    "        image_files = glob.glob(full_path)\n",
    "        if image_files:\n",
    "            img = plt.imread(image_files[0])\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            predicted_class = y_pred_classes[frame_number]\n",
    "            truth = y_true[frame_number]\n",
    "            plt.title(f\"{'Correct' if correct else 'Incorrect'} Prediction for Patient {patient_id}\\nPredicted: {predicted_class}, Truth: {truth}\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No image found for frame {frame_number} and patient {patient_id}\")\n",
    "\n",
    "    for idx in correct_to_visualize:\n",
    "        display_image(idx, patient_ids[idx % len(patient_ids)], correct=True)\n",
    "\n",
    "    for idx in incorrect_to_visualize:\n",
    "        display_image(idx, patient_ids[idx % len(patient_ids)], correct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    patient_ids = range(5, 12)\n",
    "    emg_data, eeg_data = load_data(patient_ids)\n",
    "    print(f\"Number of frames in EMG data: {len(emg_data)}\")\n",
    "    print(f\"Number of frames in EEG data: {len(eeg_data)}\")\n",
    "    \n",
    "    all_classes = load_classes()\n",
    "    print(f\"Number of frames in all classes: {len(all_classes)}\")    \n",
    "\n",
    "    X, y = prepare_dataset(emg_data, eeg_data, all_classes)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "    X_train = X_train.reshape((-1, 15, 30, 1))\n",
    "    X_test = X_test.reshape((-1, 15, 30, 1))\n",
    "\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "\n",
    "    y_train = ensure_one_hot_encoding(y_train)\n",
    "    y_test = ensure_one_hot_encoding(y_test)\n",
    "\n",
    "    print(f\"y_train shape (after check): {y_train.shape}\")\n",
    "    print(f\"y_test shape (after check): {y_test.shape}\")\n",
    "        \n",
    "    model = cnn_model(lr=1e-4)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    all_classes = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "    print(f\"Length of all_classes: {len(all_classes)}\")\n",
    "    print(f\"Content of all_classes: {all_classes}\")\n",
    "    all_classes_str = [str(c) for c in all_classes]  \n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=all_classes_str))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plot_confusion_matrix(cm, classes=all_classes_str)\n",
    "    plt.show()\n",
    "\n",
    "    evaluation_results = model.evaluate(X_test, y_test, verbose=2)\n",
    "    test_loss, test_accuracy = evaluation_results[:2]\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    model.save('C:\\\\Users\\\\MindRove_BZs\\\\Diploma\\\\models\\\\model_results.h5')\n",
    "    plot(history.history['loss'], history.history['val_loss'], history.history['accuracy'], history.history['val_accuracy'])\n",
    "\n",
    "    visualize_results(y_true, y_pred_classes, list(patient_ids))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
