{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install imbalanced-learn\n",
    "import sys\n",
    "# %%\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure compatibility with different TensorFlow versions\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\MindRove_BZs\\\\Diploma\\\\processed_data_notch_norm\\\\'\n",
    "class_dir = 'C:\\\\Users\\\\MindRove_BZs\\\\Diploma\\\\classes\\\\'\n",
    "\n",
    "def load_data(patient_ids):\n",
    "    emg_data = {}\n",
    "    eeg_data = {}\n",
    "    for i in patient_ids:\n",
    "        with open(os.path.join(data_dir, f'normalized_filtered_emg_data_patient_{i}.pkl'), 'rb') as f:\n",
    "            patient_emg_data = pickle.load(f)\n",
    "            for key in patient_emg_data:\n",
    "                if isinstance(key, float) and key.is_integer():\n",
    "                    key = int(key) \n",
    "                modified_key = f\"patient_{i}_{key}\"\n",
    "                emg_data[modified_key] = patient_emg_data[key]\n",
    "        \n",
    "        with open(os.path.join(data_dir, f'normalized_filtered_eeg_data_patient_{i}.pkl'), 'rb') as f:\n",
    "            patient_eeg_data = pickle.load(f)\n",
    "            for key in patient_eeg_data:\n",
    "                if isinstance(key, float) and key.is_integer():\n",
    "                    key = int(key)  \n",
    "                modified_key = f\"patient_{i}_{key}\"\n",
    "                eeg_data[modified_key] = patient_eeg_data[key]\n",
    "        print(f\"Size of eeg data after patient {i}: {len(eeg_data)}\")\n",
    "    \n",
    "    return emg_data, eeg_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_classes():\n",
    "    class_files = [f for f in os.listdir(class_dir) if f.endswith('.pickle')]\n",
    "    all_classes = {}\n",
    "    for file in class_files:\n",
    "        with open(os.path.join(class_dir, file), 'rb') as f:\n",
    "            classes_data = pickle.load(f)\n",
    "            identifier = file.split('_')[-1].replace('.pickle', '')\n",
    "            for key in classes_data:\n",
    "                modified_key = f\"patient_{identifier}_{key}\"\n",
    "                all_classes[modified_key] = classes_data[key]\n",
    "    return all_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pca_data():\n",
    "    base_path = \"C:\\\\Users\\\\MindRove_BZs\\\\Diploma\\\\pca_labels\"\n",
    "    pca_data = {}\n",
    "    for i in range(5, 12):\n",
    "        file_path = os.path.join(base_path, f\"{i}_pca_transformed_data.csv\")\n",
    "        with open(file_path, 'r') as f:\n",
    "            identifier = file_path.split('_')[0].split('\\\\')[-1]\n",
    "            #print(f\"Identifier: {identifier}\")\n",
    "            for line in f:  \n",
    "                parts = line.strip().split(',')  \n",
    "                frame_number = parts[0]  \n",
    "                #print(f\"Frame number: {frame_number} \")\n",
    "                data = [float(x) for x in parts[1:]] \n",
    "                modified_key = f\"patient_{i}_{frame_number}\" \n",
    "                #print(f\"Modified key: {modified_key}\")\n",
    "                pca_data[modified_key] = data \n",
    "\n",
    "    return pca_data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(emg_data, eeg_data):\n",
    "    channels_to_keep = np.r_[0:6, 7:8]\n",
    "\n",
    "    filtered_emg_data = {}\n",
    "    filtered_eeg_data = {}\n",
    "    for frame in emg_data:\n",
    "        if emg_data[frame].shape[1] >= 30 and eeg_data[frame].shape[1] >= 30:\n",
    "            min_length = 30\n",
    "            filtered_emg_data[frame] = emg_data[frame][channels_to_keep][:, :min_length]\n",
    "            filtered_eeg_data[frame] = eeg_data[frame][channels_to_keep][:, :min_length]\n",
    "    return filtered_emg_data, filtered_eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(emg_data, eeg_data, all_classes):\n",
    "    filtered_emg_data, filtered_eeg_data = filter_data(emg_data, eeg_data)\n",
    "    X = []\n",
    "    y = []\n",
    "    for frame in all_classes.keys():\n",
    "        #print(f\"Frame: {frame}\")\n",
    "        if frame in filtered_emg_data and frame in filtered_eeg_data:\n",
    "            combined_data = np.concatenate((filtered_emg_data[frame], filtered_eeg_data[frame]), axis=0)\n",
    "            X.append(combined_data)\n",
    "            y.append(all_classes[frame])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "    \n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "\n",
    "def euclidean_distance(y_true, y_pred):\n",
    "    euclidean_distances = tf.sqrt(tf.reduce_sum(tf.square(y_pred - y_true), axis=-1))\n",
    "    return tf.reduce_mean(euclidean_distances)\n",
    "\n",
    "def lstm_model(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, return_sequences=True, input_shape=(X.shape[1], X.shape[2]), dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(0.2))  \n",
    "    model.add(Dense(units=60, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae', tf.metrics.mean_squared_error, euclidean_distance])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(loss, val_loss, acc, val_acc, euclidean_distance, val_euclidean_distance):\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, acc, 'b-', label='Training MAE')\n",
    "    plt.plot(epochs, val_acc, 'r-', label='Validation MAE')\n",
    "    plt.title('Training and Validation MAE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, euclidean_distance, 'b-', label='Training Euclidean Distance')\n",
    "    plt.plot(epochs, val_euclidean_distance, 'r-', label='Validation Euclidean Distance')\n",
    "    plt.title('Training and Validation Euclidean Distance')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    patient_ids = range(5, 12)\n",
    "    emg_data, eeg_data = load_data(patient_ids)\n",
    "    print(f\"Number of frames in EMG data: {len(emg_data)}\")\n",
    "    print(f\"Number of frames in EEG data: {len(eeg_data)}\")\n",
    "    \n",
    "    all_classes = load_pca_data()\n",
    "    print(f\"Number of frames in all classes: {len(all_classes)}\")    \n",
    "\n",
    "    X, y = prepare_dataset(emg_data, eeg_data, all_classes)\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "    X_train = X_train.reshape((-1, 14, 30, 1))\n",
    "    X_test = X_test.reshape((-1, 14, 30, 1))\n",
    "    \n",
    "    model = lstm_model(X_train, y_train)\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=100, verbose = 1)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Predictions (subset):\", y_pred[:10])\n",
    "    print(\"Actual (subset):\", y_test[:10])\n",
    "\n",
    "    model.save('lstm_model.h5')\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    euc_distance = euclidean_distance(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"Euclidean Distance: {euc_distance}\")\n",
    "\n",
    "    plot(history.history['loss'], history.history['val_loss'], history.history.get('mae'), history.history.get('val_mae'), history.history.get('euclidean_distance'), history.history.get('val_euclidean_distance'))\n",
    "\n",
    "    random_indices = np.random.choice(len(y_test), min(10, len(y_test)), replace=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.plot(y_test[idx], label='Actual')\n",
    "        plt.plot(y_pred[idx], label='Predicted', alpha=0.7)\n",
    "        plt.title(f'Sample {idx+1}')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Plot for Loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Plot for MAE\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if 'mae' in history.history:\n",
    "        plt.plot(history.history['mae'], label='Train MAE')\n",
    "        plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "        plt.title('Model MAE')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "    # Plot for Euclidean Distance\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'euclidean_distance' in history.history:\n",
    "        plt.plot(history.history['euclidean_distance'], label='Train Euclidean Distance')\n",
    "        plt.plot(history.history['val_euclidean_distance'], label='Validation Euclidean Distance')\n",
    "        plt.title('Euclidean Distance')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
